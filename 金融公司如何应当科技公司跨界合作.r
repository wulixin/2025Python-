
# åŠ è½½åŒ…
library(DALEX)
library(ggplot2)
library(dplyr)

set.seed(42)
n <- 1000

# ç”ŸæˆåŸºç¡€æ•°æ®
data <- data.frame(
  loan_id = 1:n,
  age_years = runif(n, 1, 20),
  annual_revenue = exp(rnorm(n, mean = 10, sd = 0.8)) / 1e4 * 1000,  # ç™¾ä¸‡çº§è¥æ”¶
  profit_margin = pmax(pmin(rnorm(n, 8, 5), 25), 1),                 # å‡€åˆ©æ¶¦ç‡ 1~25%
  debt_ratio = rbeta(n, 2, 3) * 100,                                  # èµ„äº§è´Ÿå€ºç‡
  credit_score_bank = pmax(pmin(round(rnorm(n, 650, 100)), 850), 300), # é“¶è¡Œä¿¡ç”¨åˆ†
  use_b_platform = sample(c(TRUE, FALSE), n, prob = c(0.6, 0.4), replace = TRUE) # æ˜¯å¦ä½¿ç”¨Bå¹³å°
)

# æ ¹æ® use_b_platform å†³å®šäº¤æ˜“é¢å’Œå±¥çº¦ç‡
data$transaction_volume_b <- ifelse(
  data$use_b_platform,
  rexp(n, 1/50),   # å¹³å‡50ä¸‡çš„æŒ‡æ•°åˆ†å¸ƒ
  0
)

data$on_time_delivery_rate <- ifelse(
  data$use_b_platform,
  rbeta(n, 8, 1.5) * 100,  # é«˜å‡†æ—¶ç‡
  NA                    # ä¸ä½¿ç”¨è€…è®¾ä¸ºç¼ºå¤±
)

# å…¶ä»–å­—æ®µ
data$employee_count <- sample(c(10, 20, 50, 100), n, replace = TRUE,
                              prob = c(0.4, 0.3, 0.2, 0.1))
data$has_physical_factory <- sample(c(1, 0), n, replace = TRUE, prob = c(0.7, 0.3))
data$region_risk_level <- sample(1:3, n, replace = TRUE, prob = c(0.5, 0.3, 0.2))
data$loan_amount_requested <- runif(n, 50, 500)

# å¡«è¡¥ on_time_delivery_rate ç¼ºå¤±å€¼ï¼ˆç”¨ä¸­ä½æ•°ï¼‰
median_delivery <- median(data$on_time_delivery_rate, na.rm = TRUE)
data$on_time_delivery_rate[is.na(data$on_time_delivery_rate)] <- median_delivery

# åˆ é™¤ä¸´æ—¶åˆ—
data$use_b_platform <- NULL

# æŸ¥çœ‹å‰å‡ è¡Œ
head(data)


# å®šä¹‰ç‰¹å¾å˜é‡
features <- c(
  "age_years",
  "annual_revenue",
  "profit_margin",
  "debt_ratio",
  "credit_score_bank",
  "transaction_volume_b",
  "on_time_delivery_rate",
  "employee_count",
  "has_physical_factory",
  "region_risk_level",
  "loan_amount_requested"
)


# æ„é€ å®¡æ‰¹ç›®æ ‡å˜é‡ï¼ˆåŸºäºç»¼åˆè¯„åˆ†ï¼‰
X_score <- (
  0.02 * data$age_years +
    0.0001 * data$annual_revenue +
    0.1 * data$profit_margin -
    0.03 * data$debt_ratio +
    0.005 * data$credit_score_bank +
    0.00005 * data$transaction_volume_b +
    0.01 * data$on_time_delivery_rate +
    0.5 * data$has_physical_factory -
    0.3 * (data$region_risk_level - 1) -
    0.001 * data$loan_amount_requested
)


# Sigmoid è½¬æ¢ä¸ºæ¦‚ç‡
prob <- 1 / (1 + exp(-(X_score - mean(X_score))))
data$approved <- as.factor(ifelse(runif(n) < prob, "Yes", "No"))

# è®­ç»ƒé›†æµ‹è¯•é›†åˆ’åˆ†
idx_train <- sample(1:n, size = 0.8 * n)
train_data <- data[idx_train, ]
test_data  <- data[-idx_train, ]
# ç¡®ä¿ approved æ˜¯å› å­ï¼Œä¸”åªä¿ç•™éœ€è¦çš„åˆ—
train_data_model <- train_data %>%
  select(all_of(features), approved)

# å»ºæ¨¡ï¼ˆä¸éœ€è¦æ‰‹åŠ¨å­é›†ä¼ å…¥ dataï¼‰
model_glm <- glm(approved ~ ., 
                 data = train_data_model, 
                 family = binomial)

# æŸ¥çœ‹ç»“æœ
summary(model_glm)

# åˆ›å»º explainer å¯¹è±¡
explainer_glm <- explain(model_glm,
                         data = select(test_data, all_of(features)),
                         y = test_data$approved == "Yes",
                         label = "Logistic Regression Model")

# æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
print(explainer_glm)

vi <- model_parts(explainer_glm)
head(vi)

# ç»˜å›¾
plot(vi, max_vars = 10) +
  ggtitle("Variable Importance (Permutation)")

# é€‰æ‹©ä¸€ä¸ªæµ‹è¯•æ ·æœ¬ï¼ˆä¾‹å¦‚ç¬¬ä¸€ä¸ªï¼‰
new_observation <- test_data[1, features]

bd <- predict_parts(explainer_glm,
                    new_observation,
                    type = "break_down")

plot(bd) +
  ggtitle("Break-down: Why This Loan Was Approved?")



shap <- predict_parts(explainer_glm,
                      new_observation,
                      type = "shap",
                      B = 25)  # è®¾ç½®é‡‡æ ·æ¬¡æ•°

plot(shap) +
  ggtitle("SHAP Values for Individual Prediction")


# ä¿¡ç”¨è¯„åˆ†çš„å½±å“
pd_credit <- model_profile(explainer_glm, variables = "credit_score_bank")
plot(pd_credit) + ggtitle("Partial Dependence: Credit Score vs Approval Probability")

# Bå¹³å°äº¤æ˜“é¢çš„å½±å“ï¼ˆä½“ç°åˆä½œä»·å€¼ï¼‰
pd_trans <- model_profile(explainer_glm, variables = "transaction_volume_b")
plot(pd_trans) + ggtitle("Impact of B-Platform Transaction Volume")


ice_trans <- model_profile(explainer_glm, type = "partial", variables = "transaction_volume_b")
plot(ice_trans) + ggtitle("Individual Conditional Expectation (ICE)")


mp <- model_performance(explainer_glm)
plot(mp)  # ROC Curve, LIFT Chart

mp$measurements %>% filter(measure %in% c("AUROC"))

mp$measurements %>% filter(measure %in% c("AUROC"))

#############################################
#
#     åŠ å…¥Bå¹³å°æ•°æ®ä¸ä¸åŠ å…¥Bå¹³å°æ•°æ®åšå¯¹æ¯”
#
##############################################
# ç¡®ä¿ features å·²æ­£ç¡®å®šä¹‰
features_full <- c(
  "age_years", "annual_revenue", "profit_margin", "debt_ratio",
  "credit_score_bank", "transaction_volume_b", "on_time_delivery_rate",
  "employee_count", "has_physical_factory", "region_risk_level",
  "loan_amount_requested"
)

# å»æ‰Bå¹³å°ç›¸å…³å­—æ®µ â†’ æ¨¡æ‹ŸAé“¶è¡Œç‹¬ç«‹å»ºæ¨¡èƒ½åŠ›
features_base <- setdiff(features_full, c("transaction_volume_b", "on_time_delivery_rate"))


library(dplyr)

# èåˆæ¨¡å‹æ•°æ®ï¼ˆå«Bå¹³å°ï¼‰
train_full <- train_data %>%
  select(all_of(features_full), approved)

test_full <- test_data %>%
  select(all_of(features_full), approved)

# åŸºç¡€æ¨¡å‹æ•°æ®ï¼ˆä¸å«Bå¹³å°ï¼‰
train_base <- train_data %>%
  select(all_of(features_base), approved)

test_base <- test_data %>%
  select(all_of(features_base), approved)



# æ¨¡å‹1ï¼šèåˆæ¨¡å‹ï¼ˆå«Bå¹³å°æ•°æ®ï¼‰
model_full <- glm(approved ~ ., data = train_full, family = binomial)

# æ¨¡å‹2ï¼šåŸºç¡€æ¨¡å‹ï¼ˆæ— Bå¹³å°æ•°æ®ï¼‰
model_base <- glm(approved ~ ., data = train_base, family = binomial)



library(DALEX)

# è§£é‡Šå™¨1ï¼šèåˆæ¨¡å‹
# è§£é‡Šå™¨1ï¼šèåˆæ¨¡å‹
explainer_full <- DALEX::explain(
  model_full,
  data = test_full[, features_full],  # æµ‹è¯•é›†X
  y = test_full$approved == "Yes",   # yä¸ºé€»è¾‘å€¼TRUE/FALSE
  label = "Model with äº¬ä¸œ Platform Data"
)

# è§£é‡Šå™¨2ï¼šåŸºç¡€æ¨¡å‹
explainer_base <- DALEX::explain(
  model = model_base,
  data = test_base[, features_base, drop = FALSE],
  y = test_base$approved == "Yes",
  label = "Model without äº¬ä¸œ Platform Data"
)

mp_full <- model_performance(explainer_full)
mp_base <- model_performance(explainer_base)

# å¯¹æ¯”ç»˜å›¾
plot(mp_full, mp_base) +
  ggtitle("ROC Curve: With vs Without äº¬ä¸œ Platform Data") +
  scale_color_brewer(type = "qual", palette = "Set1")



plot(mp_full, mp_base, geom = "lift") +
  ggtitle("Lift Chart: Model Comparison")



vi_full <- model_parts(explainer_full)
vi_base <- model_parts(explainer_base)

plot(vi_full, vi_base) +
  ggtitle("Variable Importance: Impact of Adding äº¬ä¸œ Platform Data")


# æå–ç¬¬ä¸€ä¸ªæµ‹è¯•æ ·æœ¬
new_obs_full <- test_full[1, features_full, drop = FALSE]
new_obs_base <- test_full[1, features_base, drop = FALSE]  # æ³¨æ„ï¼šä» test_full ä¸­æå–å¹¶å»é™¤ébaseåˆ—

# æŸ¥çœ‹è¯¥å®¢æˆ·ä¿¡æ¯
print("Customer Info:")
print(t(new_obs_full))


# Full æ¨¡å‹è§£é‡Š
bd_full <- predict_parts(explainer_full, new_obs_full, type = "break_down")
# Base æ¨¡å‹è§£é‡Š
bd_base <- predict_parts(explainer_base, new_obs_base, type = "break_down")

# å¯¹æ¯”ç»˜å›¾
plot(bd_full, bd_base) +
  ggtitle("Break-down: With vs Without äº¬ä¸œ Platform Data") +
  theme(legend.position = "bottom")


# SHAP è§£é‡Šï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰
shap_full <- predict_parts(explainer_full, new_obs_full, type = "shap", B = 25)
shap_base <- predict_parts(explainer_base, new_obs_base, type = "shap", B = 25)

# ç»˜å›¾å¯¹æ¯”
plot(shap_full, shap_base) +
  ggtitle("SHAP Values: Impact of äº¬ä¸œ Platform Features") +
  coord_flip()  # æ¨ªå‘æ˜¾ç¤ºæ›´æ¸…æ™°


# åˆ†æ‰¹åˆ†æå¤šä¸ªå®¢æˆ·
# å¯¹å‰5ä¸ªå®¢æˆ·åš SHAP åˆ†æ
clients_full <- test_full[1:5, features_full, drop = FALSE]
clients_base <- test_full[1:5, features_base, drop = FALSE]

shap_multi_full <- predict_parts(explainer_full, clients_full, type = "shap", B = 10)
shap_multi_base <- predict_parts(explainer_base, clients_base, type = "shap", B = 10)

plot(shap_multi_full, max_vars = 8) + ggtitle("Top Features Driving Decisions (With äº¬ä¸œ Data)")
plot(shap_multi_base, max_vars = 8) + ggtitle("Only Traditional Features Matter (No äº¬ä¸œ Data)")



#ä½¿ç”¨ ROCR åŒ…ï¼ˆæˆ–ç°ä»£æ›¿ä»£æ–¹æ¡ˆï¼‰è®¡ç®— å…¨é¢çš„æ€§èƒ½æŒ‡æ ‡è¡¨ï¼ˆTable 1 é£æ ¼ï¼‰ï¼ŒåŒ…æ‹¬ï¼š 

#åˆ†ç±»å‡†ç¡®æ€§ã€æ•æ„Ÿæ€§ã€ç‰¹å¼‚æ€§
#ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1
#æå‡åº¦ï¼ˆLiftï¼‰ã€é¢„æµ‹è¯¯å·®
#AUCã€RMSEã€äº¤å‰ç†µç­‰


#ä»è€Œæ­ç¤ºï¼šå³ä½¿ AUC å·®å¼‚å°ï¼Œå…¶ä»–å…³é”®ä¸šåŠ¡æŒ‡æ ‡ï¼ˆå¦‚ precision, recall, liftï¼‰ä»å¯èƒ½æœ‰æ˜¾è‘—æ”¹è¿›ã€‚

# åŠ è½½
library(ROCR)

# é¢„æµ‹æ¦‚ç‡ï¼ˆæ­£ç±»æ¦‚ç‡ï¼‰
prob_full <- predict(model_full, test_full, type = "response")
prob_base <- predict(model_base, test_base, type = "response")

# çœŸå®æ ‡ç­¾
true_labels <- test_full$approved  # å› ä¸º test_full å’Œ test_base æ¥è‡ªåŒä¸€å­é›†


pred_full <- prediction(prob_full, true_labels)
pred_base <- prediction(prob_base, true_labels)

library(ROCR)

compute_metrics <- function(pred_obj, label) {
  # è·å–åœ¨é˜ˆå€¼ 0.5 é™„è¿‘çš„æŒ‡æ ‡
  get_at_thres <- function(p, t = 0.5) {
    x_vals <- slot(p, 'x.values')[[1]]   # é˜ˆå€¼ or rpp
    y_vals <- slot(p, 'y.values')[[1]]
    idx <- which.min(abs(x_vals - t))
    return(y_vals[idx])
  }
  
  # è®¡ç®—å„é¡¹ performance å¯¹è±¡
  acc   <- performance(pred_obj, "acc")
  sens  <- performance(pred_obj, "sens")   # sensitivity = recall
  spec  <- performance(pred_obj, "spec")   # specificity
  prec  <- performance(pred_obj, "prec")   # precision
  fpr   <- performance(pred_obj, "fpr")    # false positive rate = fallout
  fnr   <- performance(pred_obj, "fnr")    # miss rate
  npv   <- performance(pred_obj, "npv")    # negative predictive value
  
  list(
    Model = label,
    Accuracy       = get_at_thres(acc, 0.5),
    Sensitivity    = get_at_thres(sens, 0.5),
    Specificity    = get_at_thres(spec, 0.5),
    Precision      = get_at_thres(prec, 0.5),
    Recall         = get_at_thres(sens, 0.5),  # same as sensitivity
    NPV            = get_at_thres(npv, 0.5),
    Fallout        = get_at_thres(fpr, 0.5),  # å³ FPR
    Miss_Rate      = get_at_thres(fnr, 0.5)
  )
}



# è®¡ç®—ä¸¤ä¸ªæ¨¡å‹çš„æŒ‡æ ‡
metrics_full <- compute_metrics(pred_full, "With B Platform")
metrics_base <- compute_metrics(pred_base, "Without B Platform")

# åˆå¹¶ä¸ºè¡¨æ ¼
perf_table <- rbind(as.data.frame(metrics_full), as.data.frame(metrics_base))
perf_table$F1_Score <- 2 * (perf_table$Precision * perf_table$Recall) / 
  (perf_table$Precision + perf_table$Recall)

# æ‰“å°ç»“æœ
print(perf_table, digits = 3)


auc_full <- performance(pred_full, "auc")@y.values[[1]]
auc_base <- performance(pred_base, "auc")@y.values[[1]]
cat("AUC (Full):", round(auc_full, 3), "\n")
cat("AUC (Base):", round(auc_base, 3), "\n")


lift_full <- performance(pred_full, "lift", "rpp")  # rpp = rate of positive predictions
plot(lift_full, main = "Lift Curve: With vs Without B Platform")

# è·å– top 10% æ ·æœ¬æ—¶çš„ lift å€¼
rpp_vals <- slot(lift_full, 'x.values')[[1]]
lift_vals <- slot(lift_full, 'y.values')[[1]]
lift_at_10 <- approx(rpp_vals, lift_vals,xout = 10)$y

rmse <- function(labels, probs) {
  sqrt(mean((as.numeric(labels) - 1) - probs)^2)
}
rmse_full <- rmse(true_labels, prob_full)
rmse_base <- rmse(true_labels, prob_base)


logloss <- function(labels, probs) {
  eps <- 1e-15  # é˜²æ­¢ log(0)
  probs <- pmax(pmin(probs, 1 - eps), eps)
  -mean(as.numeric(labels == "Yes") * log(probs) + 
          (1 - as.numeric(labels == "Yes")) * log(1 - probs))
}

logloss_full <- logloss(true_labels, prob_full)
logloss_base <- logloss(true_labels, prob_base)

æŒ‡æ ‡	ä¸šåŠ¡å«ä¹‰	æˆ˜ç•¥å¯ç¤º
â†‘ Recall / â†“ Miss Rate	æ›´å°‘æ¼æ‰å¥½å®¢æˆ·	å¯æ‹“å±•æœåŠ¡è¾¹ç•Œ
â†‘ Precision / â†‘ F1	å‡å°‘è¯¯æ‰¹é£é™©	æ§åˆ¶ä¸è‰¯ç‡åŒæ—¶æ‰©å¤§è§„æ¨¡
â†‘ Lift	è¥é”€èµ„æºæ›´é«˜æ•ˆ	æ¨å‡ºâ€œA+Bç™½åå•ç²¾å‡†æ¨é€â€
â†“ Log Loss	æ¦‚ç‡æ›´å¯é 	æ”¯æŒåŠ¨æ€å®šä»·ä¸é¢åº¦ç®¡ç†


logloss <- function(labels, probs) {
  eps <- 1e-15
  probs <- pmax(pmin(probs, 1 - eps), eps)
  actual <- ifelse(labels == "Yes", 1, 0)
  -mean(actual * log(probs) + (1 - actual) * log(1 - probs))
}

ll_full <- logloss(true_labels, prob_full)
ll_base <- logloss(true_labels, prob_base)


get_lift_at <- function(pred_obj, p = 0.1) {
  # p: top p% of samples (e.g., 0.1 for top 10%)
  perf_lift <- performance(pred_obj, "lift", "rpp")
  rpp <- perf_lift@x.values[[1]]
  lift <- perf_lift@y.values[[1]]
  
  # ç¡®ä¿ rpp æ˜¯æ•°å€¼å‹ï¼Œå¹¶æ’åº
  df <- data.frame(rpp = rpp, lift = lift)
  df <- df[order(df$rpp), ]
  
  # æ’å€¼è·å–æŒ‡å®šç™¾åˆ†æ¯”ä¸‹çš„ Lift
  approx(df$rpp, df$lift, xout = p)$y
}

# ä½¿ç”¨ç¤ºä¾‹
lift_at_10pct_full  <- get_lift_at(pred_full, 0.1)
lift_at_10pct_base <- get_lift_at(pred_base, 0.1)

cat("Lift @ Top 10% (Full):", round(lift_at_10pct_full, 2), "\n")
cat("Lift @ Top 10% (Base):", round(lift_at_10pct_base, 2), "\n")

final_table <- data.frame(
  Measure = c("Accuracy", "Sensitivity (Recall)", "Specificity", "Precision",
              "F1-Score", "NPV", "Fallout (FPR)", "Miss Rate (FNR)",
              "AUC", "Lift@ Top 10%", "Log Loss", "RMSE"),
  `With äº¬ä¸œ Platform` = c(
    round(metrics_full$Accuracy, 3),
    round(metrics_full$Sensitivity, 3),
    round(metrics_full$Specificity, 3),
    round(metrics_full$Precision, 3),
    round(perf_table$F1_Score[1], 3),
    round(metrics_full$NPV, 3),
    round(metrics_full$Fallout, 3),
    round(metrics_full$Miss_Rate, 3),
    round(auc_full, 3),
    round(lift_at_10pct_full, 1),
    round(ll_full, 3),
    round(rmse_full, 3)
  ),
  `Without äº¬ä¸œ Platform` = c(
    round(metrics_base$Accuracy, 3),
    round(metrics_base$Sensitivity, 3),
    round(metrics_base$Specificity, 3),
    round(metrics_base$Precision, 3),
    round(perf_table$F1_Score[2], 3),
    round(metrics_base$NPV, 3),
    round(metrics_base$Fallout, 3),
    round(metrics_base$Miss_Rate, 3),
    round(auc_base, 3),
    round(lift_at_10pct_base, 1),  # ç±»ä¼¼è®¡ç®—
    round(ll_base, 3),
    round(rmse_base, 3)
  )
)

print(final_table)
library(DT)
datatable(final_table,options = list(
  pageLength = 15))
åŸå› 	è§£é‡Š
ğŸ”¹ æ•°æ®è´¨é‡é—®é¢˜	Bå¹³å°æ•°æ®å­˜åœ¨å™ªå£°æˆ–åå·®ï¼ˆå¦‚è™šå‡äº¤æ˜“ã€åˆ·å•ï¼‰
ğŸ”¹ ç‰¹å¾å†—ä½™/å†²çª	Bå¹³å°è¡Œä¸ºä¸è´¢åŠ¡æ•°æ®é«˜åº¦ç›¸å…³ï¼Œå¼•å…¥åå¯¼è‡´è¿‡æ‹Ÿåˆ
ğŸ”¹ æ ·æœ¬åå·®	ä½¿ç”¨Bå¹³å°çš„ä¼ä¸šæœ¬èº«ä¿¡ç”¨åé«˜ï¼Œå¯¼è‡´æ¨¡å‹â€œåè§â€
ğŸ”¹ æ¨¡å‹æœªå……åˆ†è®­ç»ƒ	èåˆæ•°æ®åç‰¹å¾ç©ºé—´æ‰©å¤§ï¼Œä½†æ ·æœ¬ä¸è¶³ï¼Œå­¦ä¹ æ•ˆæœä¸‹é™
ğŸ”¹ ç¼ºä¹æ­£åˆ™åŒ–	å¤šå˜é‡å¯¼è‡´è¿‡æ‹Ÿåˆï¼Œæ³›åŒ–èƒ½åŠ›ä¸‹é™


# å“ˆå“ˆå±…ç„¶æ¨ç¿»äº†ä¹‹å‰çš„ç»“è®º

å®¢æˆ·ç‰¹å¾	ç±»å‹åˆ¤å®š
æœ‰ç”µå•†å¹³å°äº¤æ˜“è®°å½•ã€é«˜å±¥çº¦ç‡	ğŸŸ¢ ç”µå•†å‹å®¢æˆ·
æœ‰å‚æˆ¿è®¾å¤‡ã€ä¾›åº”é“¾åˆåŒã€å‡ºå£æŠ¥å…³å•	ğŸ”µ åˆ¶é€ ä¸šå®¢æˆ·
æ··åˆæ¨¡å¼ï¼ˆçº¿ä¸Šçº¿ä¸‹ç»“åˆï¼‰	ğŸŸ¡ ç»¼åˆå‹å®¢æˆ·



# æ˜¾ç¤º
print(final_table)


library(mlr3)
library(mlr3viz)
library(lime)
library(mlr3learners)
library(mlr3)
library(mlr3learners)

# --- 1. åˆ›å»ºè®­ç»ƒä»»åŠ¡ ---
task_full <- TaskClassif$new(
  id = "loan_full",
  backend = train_full,
  target = "approved"   # å¿…é¡»æŒ‡å®šç›®æ ‡åˆ—
)

# --- 2. è·å–å­¦ä¹ å™¨ ---
learner_glm <- lrn("classif.log_reg", predict_type = "prob")

# --- 3. è®­ç»ƒæ¨¡å‹ ---
model_mlr_full <- learner_glm$train(task_full)

# --- 4. åˆ›å»ºæµ‹è¯•ä»»åŠ¡ ---
task_test_full <- TaskClassif$new(
  id = "test_full",
  backend = test_full,
  target = "approved"   # åŒæ ·éœ€è¦ targetï¼
)

# --- 5. é¢„æµ‹ ---
pred_full <- model_mlr_full$predict(task_test_full)

# --- 6. æŸ¥çœ‹ç»“æœ ---
print(pred_full)
pred_full$score(msr("classif.auc"))


pred_base <- model_mlr_base$predict(task_base)

# å®šä¹‰é€»è¾‘å›å½’ learner
learner_glm <- lrn("classif.log_reg", predict_type = "prob")

# è®­ç»ƒæ¨¡å‹
model_mlr_full <- learner_glm$train(task_full)
model_mlr_base <- learner_glm$train(task_base)

# é¢„æµ‹æµ‹è¯•é›†
pred_full <- model_mlr_full$predict(TaskClassif$new("test", backend = test_full))
pred_base <- model_mlr_base$predict(TaskClassif$new("test", backend = test_base))

# æ€§èƒ½å¯¹æ¯”
as.data.table(pred_full$score()) %>% select(measure, score)
as.data.table(pred_base$score())


# åˆ›å»ºè§£é‡Šå™¨
explainer_lime_full <- lime::lime(test_full[, features_full], model_full, bin_continuous = FALSE)
explainer_lime_base <- lime::lime(test_base[, features_base], model_base, bin_continuous = FALSE)

# è§£é‡Šç¬¬ä¸€ä¸ªæ ·æœ¬
explanation_full <- lime::explain(test_full[1, features_full], explainer_lime_full, n_features = 5)
explanation_base <- lime::explain(test_base[1, features_base], explainer_lime_base, n_features = 5)

# å¯è§†åŒ–å¯¹æ¯”
plot_features(explanation_full, ncol = 1) + ggtitle("Full Model (with B data)")
plot_features(explanation_base, ncol = 1) + ggtitle("Base Model (without B data)")







